# Laboratorio 3: Analisis de Varianza (ANOVA) en R

## Introduccion

En este análisis, exploraremos el rendimiento estudiantil en dos escuelas portuguesas utilizando un conjunto de datos que contiene una variedad de características demográficas, sociales y relacionadas con la escuela. 

Nuestro objetivo principal es entender qué factores influyen en las calificaciones finales de los estudiantes.

## Cargar los datos
```{r}
datos <- read.csv("student-por.csv")
head(datos)
clc <- function() cat(rep("\n", 50)) # Esta función limpia la consola

```

## Descrición de las variables

```{r}
# Seleccionar tres variables categóricas con al menos 3 niveles cada una
variables_categoricas <- c("school", "sex", "address")
# Definir las variables independientes que deseas analizar
variables_independientes <- c("G1", "G2", "absences", "failures", "studytime", "freetime", "goout", "Dalc", "Walc", "health", "age") # nolint

variable_dependiente <- "G3"  # Puedes cambiar esta variable

residuos <- list()  # Crear una lista para almacenar los residuos
```

## Prueba de Supuestos

### Histograma G3 sin transformar

```{r histogram-G3, echo=TRUE, fig.height=4, fig.width=6}

# Histograma de G3
hist(datos$G3, main = "Distribución de Calificaciones Finales (G3)", xlab = "Calificación Final (G3)", ylab = "Frecuencia" ) # # nolint
```

El histograma de G3 muestra una forma de campana, lo que sugiere una distribución aproximadamente normal, pero también destaca la presencia de valores iniciales que pueden estar afectando la normalidad aparente de la distribución.

### Prueba shapiro-wilk de G3 sin transformar
```{r}
shapiro.test(datos$G3)
```

W = 0.92598, p-value < 2.2e-16

Segun la prueba de Shapiro-Wilk podemos decir que la variable G3 no sigue una distribución normal dado que el p-value es menor a 0.05

### Prueba de Anderson-Darling para normalidad
```{r}
if (!require(nortest)) {
  install.packages("nortest")
  library(nortest)
}
# Prueba de Anderson-Darling para normalidad
ad.test(datos$G3)
```

A = 8.2336, p-value < 2.2e-16

Segun la prueba de Anderson-Darling podemos decir que la variable G3 no sigue una distribución normal dado que el p-value es menor a 0.05

## Anova para G3 sin transformar a partir de las variables independientes
```{r}

# Crear una lista para almacenar los resultados de los ANOVAs
resultados_anova <- list()

# Realizar un bucle para realizar ANOVAs para cada variable independiente
for (variable in variables_independientes) {
  formula_anova <- as.formula(paste("G3 ~", variable))
  resultado_anova <- aov(formula_anova, data = datos)
  resultados_anova[[variable]] <- summary(resultado_anova)
}

# Ver los resultados de los ANOVAs
for (variable in variables_independientes) {
  cat("Resultados ANOVA para", variable, ":\n")
  print(resultados_anova[[variable]])
  cat("\n")
}
```

Según los resultados de los ANOVAs, se observa que las siguientes variables tienen un valor p menor a 0.05, lo que indica que son significativas para explicar las diferencias en las calificaciones finales (G3) en el modelo: 
G1, G2, absences, failures, studytime, goout, Dalc, Walc, health y age

Específicamente, las siguientes variables son las que tienen p-valores significativamente bajos y cercanos a 0.05  
    - 'absences' (p-valor = 0.0199)
    - 'freetime' (p-valor = 0.00174)
    - 'goout' (p-valor = 0.0256)
    - 'health' (p-valor = 0.0117)
    - age' (p-valor = 0.00661) 

Por lo tanto, podemos concluir que estas variables son estadísticamente significativas para explicar las diferencias en las calificaciones finales (G3) en el modelo, mientras que las demás no aportan evidencia estadística significativa en relación con G3.

## Transformación logaritmica de la variable G3 para normalizarla

```{r}
constante <- 1  # Puedes ajustar esta constante según sea necesario
datos$G3_transformed <- log(datos$G3 + constante)

# Verificar la distribución después de la transformación
hist(datos$G3_transformed, main = "Distribución de Calificaciones Finales Transformadas", xlab = "Calificación Final (G3_transformed)", ylab = "Frecuencia") # nolint

# Realizar la prueba de Shapiro-Wilk nuevamente
shapiro_test_result_transformed <- shapiro.test(datos$G3_transformed) # nolint

# Mostrar resultado
cat("\nPrueba de Shapiro-Wilk para normalidad en G3 transformada:\n")
print(shapiro_test_result_transformed)

# Interpretación
if (shapiro_test_result_transformed$p.value < 0.05) {
  cat("Según la prueba de Shapiro-Wilk, G3 transformada no sigue una distribución normal (p-value <", shapiro_test_result_transformed$p.value, ")\n") # nolint
} else {
  cat("Según la prueba de Shapiro-Wilk, G3 transformada sigue una distribución normal (p-value =", shapiro_test_result_transformed$p.value, ")\n") # nolint
}
```

W = 0.56136, p-value < 2.2e-16

Al realizar la prueba de Shapiro-Wilk nuevamente, se observa que el valor p es menor a 0.05, lo que indica que la variable G3_transformed no sigue una distribución normal.
Para este caso no se realizaran mas transformaciones.


## Boxplot de residuos vs. variables categóricas

```{r}
# Ajustar el modelo lineal para G3 vs. school
modelo_school <- lm(G3 ~ school, data = datos)
residuos_school <- resid(modelo_school)

# Ajustar el modelo lineal para G3 vs. sex
modelo_sex <- lm(G3 ~ sex, data = datos)
residuos_sex <- resid(modelo_sex)

# Ajustar el modelo lineal para G3 vs. address
modelo_address <- lm(G3 ~ address, data = datos)
residuos_address <- resid(modelo_address)

# Boxplot de residuos vs. variables categóricas
par(mfrow = c(1, 3))

boxplot(residuos_school ~ datos$school, main = "Residuos vs. school", xlab = "school", ylab = "Residuos") # nolint
boxplot(residuos_sex ~ datos$sex, main = "Residuos vs. sex", xlab = "sex", ylab = "Residuos") # nolint
boxplot(residuos_address ~ datos$address, main = "Residuos vs. address", xlab = "address", ylab = "Residuos") # nolint

par(mfrow = c(1, 1))  # Restaurar la disposición de gráficos
```

Al apreciar que los residuos tienen una dispersión similar se podria cumplir el supuesto de homocedasticidad. Pera para estas variables variables_categoricas

## Boxplot de residuos vs. variables independientes

```{r}
# Crear una lista para almacenar los residuos de las variables independientes
residuos_independientes <- list()

# Ajustar modelos lineales para G3 vs. cada variable independiente y almacenar los residuos # nolint
for (variable in variables_independientes) {
  modelo <- lm(paste("G3 ~", variable), data = datos)
  residuos_independientes[[variable]] <- resid(modelo)
}

# Crear boxplots de residuos vs. variables independientes
par(mfrow = c(3, 4)) # Esto crea una matriz de gráficos para todas las variables independientes # nolint

for (i in seq_along(variables_independientes)) {
  boxplot(residuos_independientes[[variables_independientes[i]]] ~ datos[[variables_independientes[i]]],  # nolint
          main = paste("Residuos vs.", variables_independientes[i]),
          xlab = variables_independientes[i], ylab = "Residuos")
}

par(mfrow = c(1, 1)) # Restaurar la disposición de gráficos

```

Tambien se puede apreciar que los residuos tienen una dispersión similar para las variables independientes, por lo que se podria cumplir el supuesto de homocedasticidad. pero en G1, G2 y absences se puede apreciar que los residuos tienen una dispersión diferente, por lo que no se cumple el supuesto de homocedasticidad.


### Independencia de observaciones

```{r}
# Establecer el diseño de la matriz para los gráficos
par(mfrow = c(3, 4))

# Crear gráficos de residuos vs. número de observación para todas las variables independientes # nolint
for (i in seq_along(variables_independientes)) {
  variable <- variables_independientes[i]
  if (all(is.finite(residuos_independientes[[variable]]))) {
    plot(num_observacion, residuos_independientes[[variable]],
         main = paste("Residuos vs. Número de Observación -", variable),
         xlab = "Número de Observación", ylab = "Residuos")
  } else {
         cat("No se pudo crear el gráfico para", variable, "debido a valores no finitos en los residuos.\n") # nolint
  }
}

# Restaurar la disposición de gráficos
par(mfrow = c(1, 1))
```

